{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJXW_DgiSebM"
      },
      "source": [
        "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating our Tool Belt\n",
        "  4. Creating Our State\n",
        "  5. Creating and Compiling A Graph!\n",
        "\n",
        "- ü§ù Breakout Room #2:\n",
        "  1. Evaluating the LangGraph Application with LangSmith\n",
        "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
        "  3. LangGraph for the \"Patterns\" of GenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQ3nRAgoF67"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7pQDUhUnIo8"
      },
      "source": [
        "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "### Why Cycles?\n",
        "\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "### Why LangGraph?\n",
        "\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_fLDElOVoop"
      },
      "source": [
        "## Task 1:  Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujPjGJuoPwg"
      },
      "source": [
        "## Task 2: Environment Variables\n",
        "\n",
        "We'll want to set our OpenAI, Tavily, and LangSmith API keys along with our LangSmith environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkla2fpx28QK",
        "outputId": "52d7ad22-fcb1-4abe-853b-216c55a12650"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE8 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRyQmEAVzua"
      },
      "source": [
        "## Task 3: Creating our Tool Belt\n",
        "\n",
        "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
        "\n",
        "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain-community/tree/main/libs/community) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
        "\n",
        "We'll leverage:\n",
        "\n",
        "- [Tavily Search Results](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
        "- [Arxiv](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/arxiv/tool.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6n_Dob2F46"
      },
      "source": [
        "#### üèóÔ∏è Activity #1:\n",
        "\n",
        "Please add the tools to use into our toolbelt.\n",
        "\n",
        "> NOTE: Each tool in our toolbelt should be a method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/sh/s3x19_215t70xs6m6g0vmssm0000gn/T/ipykernel_23456/1203815797.py:4: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(max_results=5)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "tool_belt = [\n",
        "    tavily_tool,\n",
        "    ArxivQueryRun(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI-C669ZYVI5"
      },
      "source": [
        "### Model\n",
        "\n",
        "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
        "\n",
        "- OpenAI's GPT-3.5 and GPT-4\n",
        "- Anthropic's Claude\n",
        "- Google's Gemini\n",
        "\n",
        "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      },
      "source": [
        "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "outputs": [],
      "source": [
        "model = model.bind_tools(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzuGo6W18Lr"
      },
      "source": [
        "#### ‚ùì Question #1:\n",
        "\n",
        "How does the model determine which tool to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Answer\n",
        "When binding a tool to the tool_belt, LangChain converts each tool into a function schema that contains all the necessary information (tool name, tool description, parameters and arguments) for the LLM to make a decision on whether to use a particular tool for the goal its trying to achieve. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_296Ub96Z_H8"
      },
      "source": [
        "## Task 4: Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsMhfO9grLu"
      },
      "source": [
        "## Task 5: It's Graphing Time!\n",
        "\n",
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
        "\n",
        "Let's create some nodes and expand on our diagram.\n",
        "\n",
        "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "tool_node = ToolNode(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      },
      "source": [
        "Now we have two total nodes. We have:\n",
        "\n",
        "- `call_model` is a node that will...well...call the model\n",
        "- `tool_node` is a node which can call a tool\n",
        "\n",
        "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vF4_lgtmQNo",
        "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x10fe16e40>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "uncompiled_graph = StateGraph(AgentState)\n",
        "\n",
        "uncompiled_graph.add_node(\"agent\", call_model)\n",
        "uncompiled_graph.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8CjRlbVmRpW"
      },
      "source": [
        "Let's look at what we have so far:\n",
        "\n",
        "![image](https://i.imgur.com/md7inqG.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXHpPeSnOWC"
      },
      "source": [
        "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGCbaYqRnmiw",
        "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x10fe16e40>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsfGoSpoF9U"
      },
      "source": [
        "![image](https://i.imgur.com/wNixpJe.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      },
      "source": [
        "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
        "\n",
        "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
        "\n",
        "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
        "\n",
        "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BZgb81VQf9o",
        "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x10fe16e40>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  return END\n",
        "\n",
        "uncompiled_graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvhcf4jp0Ce"
      },
      "source": [
        "Let's visualize what this looks like.\n",
        "\n",
        "![image](https://i.imgur.com/8ZNwKI5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjWJCkrJb9"
      },
      "source": [
        "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcgbHf1rIXZ",
        "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x10fe16e40>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiWDwBQtrw7Z"
      },
      "source": [
        "Let's look at the final visualization.\n",
        "\n",
        "![image](https://i.imgur.com/NWO7usO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYqDpErlsCsu"
      },
      "source": [
        "All that's left to do now is to compile our workflow - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "outputs": [],
      "source": [
        "simple_agent_graph = uncompiled_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNWIwBL1W4Q"
      },
      "source": [
        "#### ‚ùì Question #2:\n",
        "\n",
        "Is there any specific limit to how many times we can cycle?\n",
        "\n",
        "If not, how could we impose a limit to the number of cycles?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Answer #2 \n",
        "In theory there is no limit to how many cycles can be taken, but we are limited by the context window and should also take into account cost. Since each time the full state is sent to the LLM, cost can accumulate quickly after a few turns. \n",
        "\n",
        "For that reason, imposing some limit on the number of cycles is definitely a good idea, especially in scenarios where agents are allowed to continue without user feedback or input, since they can (willingly or unwillingly) get rack up cycles\n",
        "\n",
        "To impose a limit, you can either:\n",
        "Check the message count in your conditional edge function and return END when it exceeds a threshold\n",
        "Use the recursion_limit parameter when compiling the graph to set a hard cap on cycles\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEYcTShCsPaa"
      },
      "source": [
        "## Using Our Graph\n",
        "\n",
        "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
        "\n",
        "Let's try out a few examples to see how it fairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Technical professionals are using AI in various ways to enhance their work, including automating repetitive tasks, improving decision-making, analyzing large datasets, developing new products and services, and optimizing processes. They leverage AI for tasks such as machine learning model development, natural language processing, computer vision, predictive analytics, and automation of workflows. This integration helps increase efficiency, accuracy, and innovation across different industries. Would you like specific examples or insights into particular fields?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 163, 'total_tokens': 253, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLdNRP4xUf55Q5VrrCuulDv20XRgF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d1f40026-7fb2-4979-b0de-ce85074f2ceb-0', usage_metadata={'input_tokens': 163, 'output_tokens': 90, 'total_tokens': 253, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"How are technical professionals using AI to improve their work?\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHnUtLSscRr"
      },
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "1. Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
        "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
        "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
        "5. The agent node added a response to the state object and passed it along the conditional edge\n",
        "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
        "\n",
        "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_16mBi9TvPibH4UWN3j9CIkwj', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_52fGG8kLUC5HFWv0prMX5sRy', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research paper\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 182, 'total_tokens': 241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLdU0XMRccJeffvtsgKjRmbnYM6WI', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d14923b-5d6e-4728-a916-3a2c6f427b5a-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_16mBi9TvPibH4UWN3j9CIkwj', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'A Comprehensive Survey of Deep Research paper'}, 'id': 'call_52fGG8kLUC5HFWv0prMX5sRy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 59, 'total_tokens': 241, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: arxiv\n",
            "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='e81c114f-1cba-4f25-8545-afda6fe63c8c', tool_call_id='call_16mBi9TvPibH4UWN3j9CIkwj'), ToolMessage(content='[{\"title\": \"[2506.12594] A Comprehensive Survey of Deep Research\", \"url\": \"https://arxiv.org/abs/2506.12594\", \"content\": \"|  |  |\\\\n --- |\\\\n| Comments: | 95 pages, 11 figures |\\\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\\\n| ACM classes: | I.2.8 |\\\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\\\n|  |  arXiv-issued DOI via DataCite |\\\\n\\\\n## Submission history\\\\n\\\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\\\n\\\\nFull-text links:\\\\n\\\\n## Access Paper: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\\\n\\\\n> cs > arXiv:2506.12594\\\\n\\\\n# Computer Science > Artificial Intelligence\\\\n\\\\narXiv:2506.12594 (cs)\\\\n\\\\n[Submitted on 14 Jun 2025]\\\\n\\\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\\\n\\\\nAuthors:Renjun Xu, Jingwen Peng [...] > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through\", \"score\": 0.89501935}, {\"title\": \"A Comprehensive Survey of Deep Research\", \"url\": \"https://arxiv.org/pdf/2506.12594?\", \"content\": \"Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] development, with specific attention to emerging architectures and integration opportunities The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9). [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches\", \"score\": 0.7978881}, {\"title\": \"A Comprehensive Survey of Deep Research: Systems ...\", \"url\": \"https://arxiv.org/html/2506.12594v1\", \"content\": \"This survey specifically examines systems that exhibit at least two of the three core dimensions, with a focus on those incorporating large language models as their foundational reasoning engine. Our scope encompasses commercial offerings such as OpenAI/DeepResearch (OpenAI, 2025), Google‚Äôs Gemini/DeepResearch (Google, 2024), and Perplexity/DeepResearch (Perplexity, 2025), alongside open-source implementations including dzhng/deep-research (Zhang, 2025), HKUDS/Auto-Deep-Research (Hong Kong [...] The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9).\\\\n\\\\n## 2. The Evolution and Technical Framework of Deep Research [...] ### 1.1. Definition and Scope of Deep Research\\\\n\\\\nDeep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions:\\\\n\\\\n1. (1)\\\\n\\\\n   Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources\\\\n2. (2)\", \"score\": 0.7402687}, {\"title\": \"Deep Research Tools: A Comprehensive Guide and ...\", \"url\": \"https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122\", \"content\": \"refine your query or add filters (like specifying a date range or field of study) and it will update the results near-instantly. The model‚Äôs summarization for each paper is done on the fly but it‚Äôs quite fast. One reason it‚Äôs speedy is that it doesn‚Äôt generate a huge narrative, it‚Äôs pulling bite-sized info (which is easier and quicker for an AI to produce). Also, much of the heavy lifting (searching papers) is done through efficient information retrieval systems. In short, among our list, [...] making it great when you need information quickly without waiting around. [...] answer (synthesized) to your question and cite a couple of papers as references. This can be useful for a quick answer, but if you need a comprehensive report, you would likely use the paper findings it gives to write your own synthesis. In terms of accuracy, Elicit is strong because it uses published papers as the source of truth. It‚Äôs basically doing an AI-powered literature review. There‚Äôs little hallucination in the sense of making up facts ‚Äî it usually quotes or summarizes what‚Äôs in the\", \"score\": 0.44391435}, {\"title\": \"In-Depth Analysis of the Latest Deep Research Technology\", \"url\": \"https://huggingface.co/blog/exploding-gradients/deepresearch-survey\", \"content\": \"##### Summary [...] follows:\", \"score\": 0.38706517}]', name='tavily_search_results_json', id='8f15518a-1e35-4e8f-9ed4-90a03f697b05', tool_call_id='call_52fGG8kLUC5HFWv0prMX5sRy', artifact={'query': 'A Comprehensive Survey of Deep Research paper', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/abs/2506.12594', 'title': '[2506.12594] A Comprehensive Survey of Deep Research', 'content': '|  |  |\\n --- |\\n| Comments: | 95 pages, 11 figures |\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\n| ACM classes: | I.2.8 |\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\n|  |  arXiv-issued DOI via DataCite |\\n\\n## Submission history\\n\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\n\\nFull-text links:\\n\\n## Access Paper: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:2506.12594\\n\\n# Computer Science > Artificial Intelligence\\n\\narXiv:2506.12594 (cs)\\n\\n[Submitted on 14 Jun 2025]\\n\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\n\\nAuthors:Renjun Xu, Jingwen Peng [...] > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through', 'score': 0.89501935, 'raw_content': None}, {'url': 'https://arxiv.org/pdf/2506.12594?', 'title': 'A Comprehensive Survey of Deep Research', 'content': 'Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] development, with specific attention to emerging architectures and integration opportunities The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9). [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches', 'score': 0.7978881, 'raw_content': None}, {'url': 'https://arxiv.org/html/2506.12594v1', 'title': 'A Comprehensive Survey of Deep Research: Systems ...', 'content': 'This survey specifically examines systems that exhibit at least two of the three core dimensions, with a focus on those incorporating large language models as their foundational reasoning engine. Our scope encompasses commercial offerings such as OpenAI/DeepResearch (OpenAI, 2025), Google‚Äôs Gemini/DeepResearch (Google, 2024), and Perplexity/DeepResearch (Perplexity, 2025), alongside open-source implementations including dzhng/deep-research (Zhang, 2025), HKUDS/Auto-Deep-Research (Hong Kong [...] The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9).\\n\\n## 2. The Evolution and Technical Framework of Deep Research [...] ### 1.1. Definition and Scope of Deep Research\\n\\nDeep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions:\\n\\n1. (1)\\n\\n   Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources\\n2. (2)', 'score': 0.7402687, 'raw_content': None}, {'url': 'https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122', 'title': 'Deep Research Tools: A Comprehensive Guide and ...', 'content': 'refine your query or add filters (like specifying a date range or field of study) and it will update the results near-instantly. The model‚Äôs summarization for each paper is done on the fly but it‚Äôs quite fast. One reason it‚Äôs speedy is that it doesn‚Äôt generate a huge narrative, it‚Äôs pulling bite-sized info (which is easier and quicker for an AI to produce). Also, much of the heavy lifting (searching papers) is done through efficient information retrieval systems. In short, among our list, [...] making it great when you need information quickly without waiting around. [...] answer (synthesized) to your question and cite a couple of papers as references. This can be useful for a quick answer, but if you need a comprehensive report, you would likely use the paper findings it gives to write your own synthesis. In terms of accuracy, Elicit is strong because it uses published papers as the source of truth. It‚Äôs basically doing an AI-powered literature review. There‚Äôs little hallucination in the sense of making up facts ‚Äî it usually quotes or summarizes what‚Äôs in the', 'score': 0.44391435, 'raw_content': None}, {'url': 'https://huggingface.co/blog/exploding-gradients/deepresearch-survey', 'title': 'In-Depth Analysis of the Latest Deep Research Technology', 'content': '##### Summary [...] follows:', 'score': 0.38706517, 'raw_content': None}], 'response_time': 1.48, 'request_id': '8c6351a4-4076-48d0-9217-038a84a127d7'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='I found the research paper titled \"A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\" authored by Renjun Xu and Jingwen Peng, published on June 14, 2025. \\n\\nNow, I will search for each of the authors to find out where they currently work.', additional_kwargs={'tool_calls': [{'id': 'call_Dkec1eZditz4cJEmybxa0Azz', 'function': {'arguments': '{\"query\": \"Renjun Xu\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_ZPmyGzpmVE0cAjgly5tNHxYR', 'function': {'arguments': '{\"query\": \"Jingwen Peng\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 119, 'prompt_tokens': 2380, 'total_tokens': 2499, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLdU83qkwNMlOKCzktuW9w28VLFhL', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--43ea0846-abad-4bc8-8269-1e57deccf200-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Renjun Xu'}, 'id': 'call_Dkec1eZditz4cJEmybxa0Azz', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jingwen Peng'}, 'id': 'call_ZPmyGzpmVE0cAjgly5tNHxYR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2380, 'output_tokens': 119, 'total_tokens': 2499, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: tavily_search_results_json\n",
            "[ToolMessage(content='[{\"title\": \"Renjun Xu - Researcher, Zhejiang University\", \"url\": \"https://openreview.net/profile?id=~Renjun_Xu1\", \"content\": \"# Renjun Xu\\\\n\\\\n### Principal Researcher, Zhejiang University\\\\n\\\\n Joined September 2021\\\\n\\\\n#### Names\\\\n\\\\nRenjun Xu (Preferred)\\\\n\\\\n Suggest Name\\\\n\\\\n#### Emails\\\\n\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\\\n\\\\n Suggest Email\\\\n\\\\n#### Personal Links\\\\n\\\\nHomepage\\\\n\\\\nDBLP\\\\n\\\\nORCID\\\\n\\\\nSemantic Scholar\\\\n\\\\n Suggest URL\\\\n\\\\n#### Career & Education History\\\\n\\\\nPrincipal Researcher\\\\n\\\\nZhejiang University(zju.edu.cn)\\\\n\\\\n2018 ‚Äì Present\\\\n\\\\n Suggest Position\\\\n\\\\n#### Advisors, Relations & Conflicts\\\\n\\\\nNo relations added\\\\n\\\\n Suggest Relation\\\\n\\\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\\\n\\\\nPresent\\\\n\\\\n Suggest Expertise\", \"score\": 0.7171114}, {\"title\": \"Renjun - NCT Wiki - Fandom\", \"url\": \"https://smtown-nctzens.fandom.com/wiki/RENJUN\", \"content\": \"Huang Renjun (Chinese: ÈªÑ‰ªÅ‰øä) referred to as RENJUN (Hangul: Îü∞Ï•î) is a Chinese singer born in Jilin on March 23, 2000. He is the main vocalist and the lead dancer of NCT DREAM and NCT U.\\\\n\\\\n## Contents\\\\n\\\\n 1 History on NCT\\\\n 2 Profile\\\\n 3 Endorsements\\\\n 4 Trivia\\\\n 5 References\\\\n 6 Links\\\\n 7 Navbox\\\\n\\\\n## History on NCT[] [...] ## Profile[]\\\\n\\\\n Stage Name: RENJUN (Îü∞Ï•î)\\\\n Zodiac Sign: Aries\\\\n Position:\\\\n  + Main Vocalist\\\\n  + Lead Dancer\\\\n Nicknames: The Prince of China, King of Losing, Golden Hands, Moomin Otaku, Injun (In-Joon), Paper Doll/Man, Shoulder Gangster, Injeolmi, The One Who Brightens The World, Pure Boy, JunJun\\\\n\\\\n## Endorsements[] [...] August 24, 2016: Made his debut on the sub-unit NCT DREAM with the first digital single, \\\\\"Chewing Gum\\\\\".\\\\n March 14, 2018: Participated on the project unit NCT 2018 with the first full album, NCT 2018 EMPATHY.\\\\n October 12, 2020: Participated on the project unit NCT 2020 with the second full album, NCT RESONANCE Pt.1.\\\\n October 12, 2020: Made his debut on the sub-unit NCT U with the second full album, NCT RESONANCE Pt.1 track songs, \\\\\"Faded In My Last Song\\\\\" and \\\\\"From Home\\\\\".\", \"score\": 0.6729558}, {\"title\": \"Renyuan Xu Honored with Prestigious NSF CAREER Award\", \"url\": \"https://viterbischool.usc.edu/news/2024/06/renyuan-xu-honored-with-prestigious-nsf-career-award/\", \"content\": \"Xu is an emerging research leader who harnesses machine learning and probability tools to improve decision-making in fields that experience a high degree of uncertainty, such as the financial and economic systems, or in public policy, such as the design of fair contracts and the allocation of social resources. [...] WiSE Gabilan Assistant Professor of Industrial and Systems Engineering Renyuan Xu has been recognized with the prestigious National Science Foundation (NSF) CAREER Award for 2024.\\u202fThe award honors early-career faculty members with the potential to serve as academic role models in research and education to lead advances in their respective fields. The NSF selects CAREER Award recipients who are building a firm foundation for a lifetime of leadership in integrating education and research. [...] Xu joined the Daniel J. Epstein Department of Industrial and Systems Engineering in 2021 following a two-year role as a Hooke Research Fellow at Oxford University‚Äôs Mathematical Institute.\\\\n\\\\nShe completed her undergraduate studies in mathematics at the University of Science and Technology of China before moving to the U.S. for her Ph.D. at UC Berkeley in the Department of Industrial Engineering and Operations Research.\", \"score\": 0.6501347}, {\"title\": \"Renjun of NCT Dream, Chinese K-pop star who is ...\", \"url\": \"https://www.scmp.com/lifestyle/entertainment/article/3100230/renjun-nct-dream-chinese-k-pop-star-who-passionate-focused\", \"content\": \"Renjun was born Huang Ren-jun in Jilin province, northeast China, in March 2000. Korean is commonly spoken in the area because it is close to the Korean peninsula, so he grew up bilingual.\\\\n\\\\nA young Renjun was not just interested in studying the Korean language, but Korean music as well. He was inspired by the boy band Exo and, in particular, the international success of the band‚Äôs Chinese member Lay.\\\\n\\\\nAdvertisement [...] K-pop, Mandopop, other Asian pop\\\\n\\\\nLifestyleEntertainment\\\\n\\\\n# Renjun of NCT Dream, Chinese K-pop star who is passionate, focused and goal-driven\\\\n\\\\n###  Renjun, born Huang Ren-jun, was so determined to become a K-pop singer that he travelled hours to go to an audition with less than a day‚Äôs notice  The singer speaks fluent Korean, having grown up near the China-Korea border, and recently released his first solo cover, of Troye Sivan‚Äôs Fools, in English\\\\n\\\\nReading Time:3 minutes\\\\n\\\\nWhy you can trust SCMP [...] While his schoolmates set their sights on university, Renjun wanted to become an idol and elected to study at the Beijing Contemporary Music School (alongside NCT band member Chenle), from where he graduated with full marks.\\\\n\\\\nAdvertisement\\\\n\\\\nSelect Voice\\\\n\\\\nChoose your listening speed\\\\n\\\\nGet through articles 2x faster\\\\n\\\\n1.25x\\\\n\\\\n250WPM\\\\n\\\\n1.25x\", \"score\": 0.5976789}, {\"title\": \"40+ \\\\\"Renjun Xu\\\\\" profiles - LinkedIn\", \"url\": \"https://www.linkedin.com/pub/dir/Renjun/Xu\", \"content\": \"Sign Up | LinkedIn \\\\n\\\\nAgree & Join LinkedIn\\\\n\\\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\\\n\\\\nSkip to main contentLinkedIn\\\\n\\\\nJoin LinkedIn\\\\n\\\\nImage 1: Profile photo Not you? \\\\n\\\\n Remove photo \\\\n\\\\nFirst name \\\\n\\\\nLast name \\\\n\\\\nEmail \\\\n\\\\nPassword (6+ characters) \\\\n\\\\nBy clicking Agree & Join, you agree to the LinkedIn User Agreement, Privacy Policy, and Cookie Policy.\\\\n\\\\n Agree & Join \\\\n\\\\nor\\\\n\\\\nAlready on Linkedin?  Sign in\\\\n\\\\nSecurity verification [...] Sign in\\\\n\\\\n Email or phone  \\\\n\\\\n Password  \\\\n\\\\nShow\\\\n\\\\nForgot password? Sign in \\\\n\\\\nor\\\\n\\\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\\\n\\\\nNew to Linkedin?  Join now [...] ‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi) \\\\n        Magyar (Hungarian) \\\\n        Bahasa Indonesia (Indonesian) \\\\n        Italiano (Italian) \\\\n        ◊¢◊ë◊®◊ô◊™ (Hebrew) \\\\n        Êó•Êú¨Ë™û (Japanese) \\\\n        ÌïúÍµ≠Ïñ¥ (Korean) \\\\n        ‡§Æ‡§∞‡§æ‡§†‡•Ä (Marathi) \\\\n        Bahasa Malaysia (Malay) \\\\n        Nederlands (Dutch) \\\\n        Norsk (Norwegian) \\\\n        ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä (Punjabi) \\\\n        Polski (Polish) \\\\n        Portugu√™s (Portuguese) \\\\n        Rom√¢nƒÉ (Romanian) \\\\n        –†—É—Å—Å–∫–∏–π (Russian) \\\\n        Svenska (Swedish) \\\\n        ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)\", \"score\": 0.48396602}]', name='tavily_search_results_json', id='4ba8bad3-8379-47b2-ac3d-4fd4c0e8f9b0', tool_call_id='call_Dkec1eZditz4cJEmybxa0Azz', artifact={'query': 'Renjun Xu', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://openreview.net/profile?id=~Renjun_Xu1', 'title': 'Renjun Xu - Researcher, Zhejiang University', 'content': '# Renjun Xu\\n\\n### Principal Researcher, Zhejiang University\\n\\n Joined September 2021\\n\\n#### Names\\n\\nRenjun Xu (Preferred)\\n\\n Suggest Name\\n\\n#### Emails\\n\\n\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\n\\n Suggest Email\\n\\n#### Personal Links\\n\\nHomepage\\n\\nDBLP\\n\\nORCID\\n\\nSemantic Scholar\\n\\n Suggest URL\\n\\n#### Career & Education History\\n\\nPrincipal Researcher\\n\\nZhejiang University(zju.edu.cn)\\n\\n2018 ‚Äì Present\\n\\n Suggest Position\\n\\n#### Advisors, Relations & Conflicts\\n\\nNo relations added\\n\\n Suggest Relation\\n\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\n\\nPresent\\n\\n Suggest Expertise', 'score': 0.7171114, 'raw_content': None}, {'url': 'https://smtown-nctzens.fandom.com/wiki/RENJUN', 'title': 'Renjun - NCT Wiki - Fandom', 'content': 'Huang Renjun (Chinese: ÈªÑ‰ªÅ‰øä) referred to as RENJUN (Hangul: Îü∞Ï•î) is a Chinese singer born in Jilin on March 23, 2000. He is the main vocalist and the lead dancer of NCT DREAM and NCT U.\\n\\n## Contents\\n\\n 1 History on NCT\\n 2 Profile\\n 3 Endorsements\\n 4 Trivia\\n 5 References\\n 6 Links\\n 7 Navbox\\n\\n## History on NCT[] [...] ## Profile[]\\n\\n Stage Name: RENJUN (Îü∞Ï•î)\\n Zodiac Sign: Aries\\n Position:\\n  + Main Vocalist\\n  + Lead Dancer\\n Nicknames: The Prince of China, King of Losing, Golden Hands, Moomin Otaku, Injun (In-Joon), Paper Doll/Man, Shoulder Gangster, Injeolmi, The One Who Brightens The World, Pure Boy, JunJun\\n\\n## Endorsements[] [...] August 24, 2016: Made his debut on the sub-unit NCT DREAM with the first digital single, \"Chewing Gum\".\\n March 14, 2018: Participated on the project unit NCT 2018 with the first full album, NCT 2018 EMPATHY.\\n October 12, 2020: Participated on the project unit NCT 2020 with the second full album, NCT RESONANCE Pt.1.\\n October 12, 2020: Made his debut on the sub-unit NCT U with the second full album, NCT RESONANCE Pt.1 track songs, \"Faded In My Last Song\" and \"From Home\".', 'score': 0.6729558, 'raw_content': None}, {'url': 'https://viterbischool.usc.edu/news/2024/06/renyuan-xu-honored-with-prestigious-nsf-career-award/', 'title': 'Renyuan Xu Honored with Prestigious NSF CAREER Award', 'content': 'Xu is an emerging research leader who harnesses machine learning and probability tools to improve decision-making in fields that experience a high degree of uncertainty, such as the financial and economic systems, or in public policy, such as the design of fair contracts and the allocation of social resources. [...] WiSE Gabilan Assistant Professor of Industrial and Systems Engineering Renyuan Xu has been recognized with the prestigious National Science Foundation (NSF) CAREER Award for 2024.\\u202fThe award honors early-career faculty members with the potential to serve as academic role models in research and education to lead advances in their respective fields. The NSF selects CAREER Award recipients who are building a firm foundation for a lifetime of leadership in integrating education and research. [...] Xu joined the Daniel J. Epstein Department of Industrial and Systems Engineering in 2021 following a two-year role as a Hooke Research Fellow at Oxford University‚Äôs Mathematical Institute.\\n\\nShe completed her undergraduate studies in mathematics at the University of Science and Technology of China before moving to the U.S. for her Ph.D. at UC Berkeley in the Department of Industrial Engineering and Operations Research.', 'score': 0.6501347, 'raw_content': None}, {'url': 'https://www.scmp.com/lifestyle/entertainment/article/3100230/renjun-nct-dream-chinese-k-pop-star-who-passionate-focused', 'title': 'Renjun of NCT Dream, Chinese K-pop star who is ...', 'content': 'Renjun was born Huang Ren-jun in Jilin province, northeast China, in March 2000. Korean is commonly spoken in the area because it is close to the Korean peninsula, so he grew up bilingual.\\n\\nA young Renjun was not just interested in studying the Korean language, but Korean music as well. He was inspired by the boy band Exo and, in particular, the international success of the band‚Äôs Chinese member Lay.\\n\\nAdvertisement [...] K-pop, Mandopop, other Asian pop\\n\\nLifestyleEntertainment\\n\\n# Renjun of NCT Dream, Chinese K-pop star who is passionate, focused and goal-driven\\n\\n###  Renjun, born Huang Ren-jun, was so determined to become a K-pop singer that he travelled hours to go to an audition with less than a day‚Äôs notice  The singer speaks fluent Korean, having grown up near the China-Korea border, and recently released his first solo cover, of Troye Sivan‚Äôs Fools, in English\\n\\nReading Time:3 minutes\\n\\nWhy you can trust SCMP [...] While his schoolmates set their sights on university, Renjun wanted to become an idol and elected to study at the Beijing Contemporary Music School (alongside NCT band member Chenle), from where he graduated with full marks.\\n\\nAdvertisement\\n\\nSelect Voice\\n\\nChoose your listening speed\\n\\nGet through articles 2x faster\\n\\n1.25x\\n\\n250WPM\\n\\n1.25x', 'score': 0.5976789, 'raw_content': None}, {'url': 'https://www.linkedin.com/pub/dir/Renjun/Xu', 'title': '40+ \"Renjun Xu\" profiles - LinkedIn', 'content': 'Sign Up | LinkedIn \\n\\nAgree & Join LinkedIn\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n\\nSkip to main contentLinkedIn\\n\\nJoin LinkedIn\\n\\nImage 1: Profile photo Not you? \\n\\n Remove photo \\n\\nFirst name \\n\\nLast name \\n\\nEmail \\n\\nPassword (6+ characters) \\n\\nBy clicking Agree & Join, you agree to the LinkedIn User Agreement, Privacy Policy, and Cookie Policy.\\n\\n Agree & Join \\n\\nor\\n\\nAlready on Linkedin?  Sign in\\n\\nSecurity verification [...] Sign in\\n\\n Email or phone  \\n\\n Password  \\n\\nShow\\n\\nForgot password? Sign in \\n\\nor\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n\\nNew to Linkedin?  Join now [...] ‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi) \\n        Magyar (Hungarian) \\n        Bahasa Indonesia (Indonesian) \\n        Italiano (Italian) \\n        ◊¢◊ë◊®◊ô◊™ (Hebrew) \\n        Êó•Êú¨Ë™û (Japanese) \\n        ÌïúÍµ≠Ïñ¥ (Korean) \\n        ‡§Æ‡§∞‡§æ‡§†‡•Ä (Marathi) \\n        Bahasa Malaysia (Malay) \\n        Nederlands (Dutch) \\n        Norsk (Norwegian) \\n        ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä (Punjabi) \\n        Polski (Polish) \\n        Portugu√™s (Portuguese) \\n        Rom√¢nƒÉ (Romanian) \\n        –†—É—Å—Å–∫–∏–π (Russian) \\n        Svenska (Swedish) \\n        ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)', 'score': 0.48396602, 'raw_content': None}], 'response_time': 2.12, 'request_id': '9902da48-cbed-428e-854e-bdfda32ea6a7'}), ToolMessage(content='[{\"title\": \"Jingwen Peng Email & Phone Number | Manulife Lead ...\", \"url\": \"https://rocketreach.co/jingwen-peng-email_28909123\", \"content\": \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\\\n   2010 - 2012 Research Analyst @ Congress Asset Management\\\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\\\n   2007 - 2007 Intern Analyst @ Bank of China\\\\n\\\\n see less  \\\\n\\\\n### Jingwen Peng Education\\\\n\\\\n   Boston University Questrom School of Business \\\\nMaster of Arts ( Mathematical Finance)\\\\n\\\\n2008 - 2009\\\\n   Peking University \\\\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\\\n\\\\n2004 - 2008\\\\n\\\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng\\'s profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\\\n\\\\n2\\\\n       hotmail.com\\\\n       libertymutualgroup.com\\\\n\\\\n   \\\\nImage 8: Bpifrance Assurance Export Employee Jingwen Peng\\'s profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\\\n\\\\n1\\\\n       bpifrance.fr\\\\n\\\\nView Similar Profiles\\\\n\\\\nTop Manulife Employees\", \"score\": 0.91156644}, {\"title\": \"US-China veterinary program at K-State celebrates ...\", \"url\": \"https://www.k-state.edu/media/newsreleases/2024-06/US-China-joint-veterinary-program-at-KState-celebrates-graduating-class-and-homecoming-event.html\", \"content\": \"of Missouri.At the homecoming event, recent graduates, current students and friends presented about their experiences in veterinary college. One student\\'s experiences included a close brush with a Kansas weather phenomenon.\\\\\"In my fourth year, I learned that I love dental procedures,\\\\\" said Jingwen Peng, a K-State Doctor of Veterinary Medicine graduate. \\\\\"While on the equine field service, I did dental [exams] on horses, mules and donkeys. Also while on equine field service, I got a bonus view of [...] ###### The recent graduates of the U.S.-China Joint Doctor of Veterinary Medicine Program received purple stethoscopes after giving presentations about their educational experiences. From left: Lei Wang, program manager for the U.S.-China Center for Animal Health, graduates Yuanjue Tan, Xingy Tang, Xiang Yu, Cong Zhu, Jingwen Peng and Hodes Family Dean Bonnie Rush. | Download this photo. [...] \\\\\"Great challenges lie in front of us, but that also comes with great possibilities. I think we have learned from the best, and now is the best time to go back to our country to witness and, more importantly, be part of the growing and developing of veterinary medicine in China.\\\\\"In addition to Peng and Tang, the May 2024 Doctor of Veterinary Medicine graduates are Xiangyu Lin from Kansas State University and Dr. Cong Zhu from the University of Minnesota. The Chinese graduates of the program will\", \"score\": 0.6972179}, {\"title\": \"Jingwen Peng - U of Rochester Simon STEM MSBA\", \"url\": \"https://www.linkedin.com/in/jpeng19\", \"content\": \"‚óè\\\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\\\n\\\\n‚óè\\\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\\\n\\\\n‚óè\\\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] - I\\'m excited to share that our consulting project with the Rochester Fire Department has been a resounding success! üéâ As part of a fantastic team‚Ä¶  \\\\nLiked by Jingwen Peng  \\\\nView Post  \\\\nActivity Image\\\\n\\\\n- I\\'m thrilled to announce the completion of my first consulting project as Project Manager with Simon Vision Consulting! Working alongside my‚Ä¶  \\\\nLiked by Jingwen Peng  \\\\nView Post  \\\\nActivity Image\", \"score\": 0.6213807}, {\"title\": \"April 2023 - K-State College of Veterinary Medicine\", \"url\": \"https://www.vet.k-state.edu/about/news-events-publications/lifelines/2023/2304.html\", \"content\": \"Hospitality Management. This year\\'s recipients from the veterinary college are: Grace Calo, Bailey Fritz, Angela Gaggiano, Valerie Haskett, Lilli Heinen, Nathan Jackson, Christina Marquez, Jingwen Peng, Katherine Stenger and Hanna Westermier.  David C. Poole, Departments of Anatomy and Physiology and Kinesiology, was invited to speak at the German National Academy of Sciences, in Leopoldina, Halle, Germany, this March. The apex physiology journal FUNCTION, editor‚Äìin-chief, professor Ole\", \"score\": 0.48996773}, {\"title\": \"Our People\", \"url\": \"https://www.hepinglaw.com/our-people.html\", \"content\": \"Ms Cheng Jingwen graduated from East China University of Political Science and Law with a bachelor\\'s degree in civil law.\\\\n    \\\\n    \\\\n  She has extensive experience in representing various clients on dispute resolution and litigation matters and has served as a member of various committees including the Women Lawyers Association of Pudong New Area in Shanghai and the Administrative Litigation Law Research Committee of the Shanghai Lawyers Association.\\\\n Glen Ma\\u200b\\\\n\\\\n  Head of Corporate [...] Our People\\\\n\\\\n Huiming Guo\\\\n\\\\n  Founding Partner\\\\n\\\\n  Mr Guo Huiming has been recognised as one of the first Top 10 Best Lawyers by the Shanghai Bureau of Justice.\\\\n    \\\\n    \\\\n  He graduated from Fudan University with a degree in international economic law.\\\\n    \\\\n    \\\\n  He has decades of experience and received public recognition from the Shanghai Bureau of Justice for his achievements in the legal services area.\\\\n Jingwen Cheng\\\\n\\\\n  Founding Partner [...] Julia Peng leads He Ping\\'s Intellectual Property practice. She has over 15 years of experience advising clients on intellectual property matters.\", \"score\": 0.28628942}]', name='tavily_search_results_json', id='7b4bdfc9-b634-4061-83ea-545752815cd8', tool_call_id='call_ZPmyGzpmVE0cAjgly5tNHxYR', artifact={'query': 'Jingwen Peng', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://rocketreach.co/jingwen-peng-email_28909123', 'title': 'Jingwen Peng Email & Phone Number | Manulife Lead ...', 'content': \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\n   2010 - 2012 Research Analyst @ Congress Asset Management\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\n   2007 - 2007 Intern Analyst @ Bank of China\\n\\n see less  \\n\\n### Jingwen Peng Education\\n\\n   Boston University Questrom School of Business \\nMaster of Arts ( Mathematical Finance)\\n\\n2008 - 2009\\n   Peking University \\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\n\\n2004 - 2008\\n\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng's profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\n\\n2\\n       hotmail.com\\n       libertymutualgroup.com\\n\\n   \\nImage 8: Bpifrance Assurance Export Employee Jingwen Peng's profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\n\\n1\\n       bpifrance.fr\\n\\nView Similar Profiles\\n\\nTop Manulife Employees\", 'score': 0.91156644, 'raw_content': None}, {'url': 'https://www.k-state.edu/media/newsreleases/2024-06/US-China-joint-veterinary-program-at-KState-celebrates-graduating-class-and-homecoming-event.html', 'title': 'US-China veterinary program at K-State celebrates ...', 'content': 'of Missouri.At the homecoming event, recent graduates, current students and friends presented about their experiences in veterinary college. One student\\'s experiences included a close brush with a Kansas weather phenomenon.\"In my fourth year, I learned that I love dental procedures,\" said Jingwen Peng, a K-State Doctor of Veterinary Medicine graduate. \"While on the equine field service, I did dental [exams] on horses, mules and donkeys. Also while on equine field service, I got a bonus view of [...] ###### The recent graduates of the U.S.-China Joint Doctor of Veterinary Medicine Program received purple stethoscopes after giving presentations about their educational experiences. From left: Lei Wang, program manager for the U.S.-China Center for Animal Health, graduates Yuanjue Tan, Xingy Tang, Xiang Yu, Cong Zhu, Jingwen Peng and Hodes Family Dean Bonnie Rush. | Download this photo. [...] \"Great challenges lie in front of us, but that also comes with great possibilities. I think we have learned from the best, and now is the best time to go back to our country to witness and, more importantly, be part of the growing and developing of veterinary medicine in China.\"In addition to Peng and Tang, the May 2024 Doctor of Veterinary Medicine graduates are Xiangyu Lin from Kansas State University and Dr. Cong Zhu from the University of Minnesota. The Chinese graduates of the program will', 'score': 0.6972179, 'raw_content': None}, {'url': 'https://www.linkedin.com/in/jpeng19', 'title': 'Jingwen Peng - U of Rochester Simon STEM MSBA', 'content': \"‚óè\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\n\\n‚óè\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\n\\n‚óè\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] - I'm excited to share that our consulting project with the Rochester Fire Department has been a resounding success! üéâ As part of a fantastic team‚Ä¶  \\nLiked by Jingwen Peng  \\nView Post  \\nActivity Image\\n\\n- I'm thrilled to announce the completion of my first consulting project as Project Manager with Simon Vision Consulting! Working alongside my‚Ä¶  \\nLiked by Jingwen Peng  \\nView Post  \\nActivity Image\", 'score': 0.6213807, 'raw_content': None}, {'url': 'https://www.vet.k-state.edu/about/news-events-publications/lifelines/2023/2304.html', 'title': 'April 2023 - K-State College of Veterinary Medicine', 'content': \"Hospitality Management. This year's recipients from the veterinary college are: Grace Calo, Bailey Fritz, Angela Gaggiano, Valerie Haskett, Lilli Heinen, Nathan Jackson, Christina Marquez, Jingwen Peng, Katherine Stenger and Hanna Westermier.  David C. Poole, Departments of Anatomy and Physiology and Kinesiology, was invited to speak at the German National Academy of Sciences, in Leopoldina, Halle, Germany, this March. The apex physiology journal FUNCTION, editor‚Äìin-chief, professor Ole\", 'score': 0.48996773, 'raw_content': None}, {'url': 'https://www.hepinglaw.com/our-people.html', 'title': 'Our People', 'content': \"Ms Cheng Jingwen graduated from East China University of Political Science and Law with a bachelor's degree in civil law.\\n    \\n    \\n  She has extensive experience in representing various clients on dispute resolution and litigation matters and has served as a member of various committees including the Women Lawyers Association of Pudong New Area in Shanghai and the Administrative Litigation Law Research Committee of the Shanghai Lawyers Association.\\n Glen Ma\\u200b\\n\\n  Head of Corporate [...] Our People\\n\\n Huiming Guo\\n\\n  Founding Partner\\n\\n  Mr Guo Huiming has been recognised as one of the first Top 10 Best Lawyers by the Shanghai Bureau of Justice.\\n    \\n    \\n  He graduated from Fudan University with a degree in international economic law.\\n    \\n    \\n  He has decades of experience and received public recognition from the Shanghai Bureau of Justice for his achievements in the legal services area.\\n Jingwen Cheng\\n\\n  Founding Partner [...] Julia Peng leads He Ping's Intellectual Property practice. She has over 15 years of experience advising clients on intellectual property matters.\", 'score': 0.28628942, 'raw_content': None}], 'response_time': 2.57, 'request_id': '1acacbed-7e73-4ecf-b0a2-22fff5951954'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Renjun Xu is currently a Principal Researcher at Zhejiang University. Jingwen Peng is currently working as a Lead Analyst in Investment Analytics at Manulife Investment Management.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 5913, 'total_tokens': 5947, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2432}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLdUES5IE4JZPkG3V2fmJWaCOGONm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--76fd8f79-0a81-4f56-8891-f6118f321ca6-0', usage_metadata={'input_tokens': 5913, 'output_tokens': 34, 'total_tokens': 5947, 'input_token_details': {'audio': 0, 'cache_read': 2432}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, then search each of the authors to find out where they work now using Tavily!\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        if node == \"action\":\n",
        "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXzDlZVz1Hnf"
      },
      "source": [
        "#### üèóÔ∏è Activity #2:\n",
        "\n",
        "Please write out the steps the agent took to arrive at the correct answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Answer\n",
        "1. Our state object was populated with our request (`HumanMessage`)\n",
        "2. The state object was passed into our entry point to the `agent` node. \n",
        "3. The agent node decides to continue and to make a function call by adding a `AIMessage` with the instructions to call the arxiv and tavily tools (`additional_kwargs={'tool_calls'..`) with the following parameters: `'{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}` and `tavily_search_results_json`\n",
        "4. The `action` node executes both tool calls to arxiv and tavily, returning `ToolMessage` objects with the retrieved information\n",
        "5. The new state is passed along the edge to the `Agent` node with the initial `HumanMessage`, `AIMessage` and `ToolMessage` messages\n",
        "6. The `agent` node adds a new `AIMessage`, using the information received by the `action` node's tool call and makes an additional tool call to the tavily function with `{'arguments': '{\"query\": \"Jingwen Peng\"}', 'name': 'tavily_search_results_json'}` and `{'arguments': '{\"query\": \"Renjun Xu\"}', 'name': 'tavily_search_results_json'}`\n",
        "7. The `action` node executes the tool call, querying the Tavily API looking for Jingwen Peng and Renjun Xu and passes that information to the state object with a `ToolMessage`\n",
        "8. Finally, the `agents` adds the final `AIMessage` containing the information found via Tavily on the two authors \n",
        "9. The conditional edge receives the state, finds no tool_calls in the final `AIMessage`, and routes to `END`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7c8-Uyarh1v"
      },
      "source": [
        "## Part 1: LangSmith Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV3XeFOT1Sar"
      },
      "source": [
        "### Pre-processing for LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wruQCuzewUuO"
      },
      "source": [
        "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "orYxBZXSxJjZ",
        "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'Deep Research typically refers to an in-depth and comprehensive investigation or analysis into a specific topic, subject, or field. It involves gathering detailed information, examining various sources, and analyzing data thoroughly to gain a profound understanding of the subject. Deep Research is often used in academic, scientific, technological, and business contexts to develop insights, inform decision-making, or advance knowledge.\\n\\nIf you are referring to a specific organization, product, or service named \"Deep Research,\" please provide more context so I can give a more precise answer.'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_inputs(input_object):\n",
        "  return {\"messages\" : [HumanMessage(content=input_object[\"text\"])]}\n",
        "\n",
        "def parse_output(input_state):\n",
        "  return {\"answer\" : input_state[\"messages\"][-1].content}\n",
        "\n",
        "agent_chain_with_formatting = convert_inputs | simple_agent_graph | parse_output\n",
        "\n",
        "agent_chain_with_formatting.invoke({\"text\" : \"What is Deep Research?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9UkCIqkpyZu"
      },
      "source": [
        "### Task 1: Creating An Evaluation Dataset\n",
        "\n",
        "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
        "\n",
        "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Who were the main authors on the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' paper?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Peng\", \"Xu\"]}   \n",
        "    },\n",
        "    ...,\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Where do the authors of the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' work now?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Zhejiang\", \"Liberty Mutual\"]}\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMXF2KAsQxs"
      },
      "source": [
        "#### üèóÔ∏è Activity #3:\n",
        "\n",
        "Please create a dataset in the above format with at least 5 questions that pertain to the cohort use-case (more information [here](https://www.notion.so/Session-4-RAG-with-LangGraph-OSS-Local-Models-Eval-w-LangSmith-26acd547af3d80838d5beba464d7e701#26acd547af3d81d08809c9c82a462bdd)), or the use-case you're hoping to tackle in your Demo Day project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CbagRuJop83E"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What are the latest applications of transformer models in computer vision according to recent research?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"attention\", \"vision\", \"transformer\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"Find research papers about retrieval-augmented generation (RAG) and explain the main benefits of this approach.\"},\n",
        "        \"outputs\": {\"must_mention\": [\"retrieval\", \"generation\", \"knowledge\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What are the current best practices for fine-tuning large language models in 2025?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"fine-tuning\", \"training\", \"LLM\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"Search for recent papers on LangChain or LangGraph and summarize their main use cases.\"},\n",
        "        \"outputs\": {\"must_mention\": [\"agent\", \"chain\", \"application\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What are the main challenges in deploying AI agents in production environments according to current research?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"production\", \"deployment\", \"challenge\"]}\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7QVFuAmsh7L"
      },
      "source": [
        "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RLfrZrgSsn85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'example_ids': ['ed7c56f1-0691-4680-b0b3-fd86731997b5',\n",
              "  '488a8def-2e4e-4369-9887-7662a2088b21',\n",
              "  '9c57f4d5-f475-4d07-b1eb-afbb1a1e9581',\n",
              "  '48b8447c-58ed-4928-81ab-1b9bbee1e8b8',\n",
              "  '2fe3ddb7-1213-44e7-beaa-1c366294ad8a'],\n",
              " 'count': 5}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Simple Search Agent - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Questions about the cohort use-case to evaluate the Simple Search Agent.\"\n",
        ")\n",
        "\n",
        "client.create_examples(\n",
        "    dataset_id=dataset.id,\n",
        "    examples=questions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRTXUrTtP9Y"
      },
      "source": [
        "### Task 2: Adding Evaluators\n",
        "\n",
        "Let's use the OpenEvals library to product an evaluator that we can then pass into LangSmith!\n",
        "\n",
        "> NOTE: Examine the `CORRECTNESS_PROMPT` below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert data labeler evaluating model outputs for correctness. Your task is to assign a score based on the following rubric:\n",
            "\n",
            "<Rubric>\n",
            "  A correct answer:\n",
            "  - Provides accurate and complete information\n",
            "  - Contains no factual errors\n",
            "  - Addresses all parts of the question\n",
            "  - Is logically consistent\n",
            "  - Uses precise and accurate terminology\n",
            "\n",
            "  When scoring, you should penalize:\n",
            "  - Factual errors or inaccuracies\n",
            "  - Incomplete or partial answers\n",
            "  - Misleading or ambiguous statements\n",
            "  - Incorrect terminology\n",
            "  - Logical inconsistencies\n",
            "  - Missing key information\n",
            "</Rubric>\n",
            "\n",
            "<Instructions>\n",
            "  - Carefully read the input and output\n",
            "  - Check for factual accuracy and completeness\n",
            "  - Focus on correctness of information rather than style or verbosity\n",
            "</Instructions>\n",
            "\n",
            "<Reminder>\n",
            "  The goal is to evaluate factual correctness and completeness of the response.\n",
            "</Reminder>\n",
            "\n",
            "<input>\n",
            "{inputs}\n",
            "</input>\n",
            "\n",
            "<output>\n",
            "{outputs}\n",
            "</output>\n",
            "\n",
            "Use the reference outputs below to help you evaluate the correctness of the response:\n",
            "\n",
            "<reference_outputs>\n",
            "{reference_outputs}\n",
            "</reference_outputs>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from openevals.prompts import CORRECTNESS_PROMPT\n",
        "print(CORRECTNESS_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QrAUXMFftlAY"
      },
      "outputs": [],
      "source": [
        "from openevals.llm import create_llm_as_judge\n",
        "\n",
        "correctness_evaluator = create_llm_as_judge(\n",
        "        prompt=CORRECTNESS_PROMPT,\n",
        "        model=\"openai:o3-mini\", # very impactful to the final score\n",
        "        feedback_key=\"correctness\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also create a custom Evaluator for our created dataset above - we do this by first making a simple Python function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def must_mention(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "  # determine if the phrases in the reference_outputs are in the outputs\n",
        "  required = reference_outputs.get(\"must_mention\") or []\n",
        "  score = all(phrase in outputs[\"answer\"] for phrase in required)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtHORUh0jZY"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What are some ways you could improve this metric as-is?\n",
        "\n",
        "> NOTE: Alternatively you can suggest where gaps exist in this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Answer #4\n",
        "- Case sensitivity: eval will fail if right answer is given but with different casing\n",
        "- No partial credit: score is binary, so answer could be somewhat right. This is especially important when adding additional required phrases\n",
        "- No context awareness: it's very naive as is. If something is mentioned in a negative way, e.g. \"Peng is NOT the author\", it would still consider it as correct\n",
        "- No synonym, variation handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1RJr349zhv7"
      },
      "source": [
        "Task 3: Evaluating\n",
        "\n",
        "All that is left to do is evaluate our agent's response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "efcf57067cf743d8b4ce059a61cbe02e",
            "53e33aae3b97490c82aec7bbb0d6ebba",
            "ad84e0e971d3455db2efe7dd0d1f803e",
            "72adef9b70dd48198b7322b6c5b113cf",
            "8a61d045ffd44ac58f3f13eb10044836",
            "041e22a9b5514e36bd4d1dac01d5d398",
            "886d762f2a7c421382efb5502c6d42a1",
            "ab91fd625bbd43afbf8c6398193a88d0",
            "716557ad09874dcb989d75f7c74424cd",
            "77d4c0ebaae045b58efc4f789c9a2360",
            "0d622ccc56264fac8fd7508dbdbe6e29"
          ]
        },
        "id": "p5TeCUUkuGld",
        "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'simple_agent, baseline-2b7d997f' at:\n",
            "https://smith.langchain.com/o/0ac46901-bbd8-4e04-a1a2-f0202cf105d3/datasets/440867e2-9a69-44e1-b13a-16a46096ceb9/compare?selectedSessions=be69acf1-7793-4f49-be0f-5f89e363eea1\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e2b8b2b461644b28fb2ad2ad12f71fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = client.evaluate(\n",
        "    agent_chain_with_formatting,\n",
        "    data=dataset.name,\n",
        "    evaluators=[correctness_evaluator, must_mention],\n",
        "    experiment_prefix=\"simple_agent, baseline\",  # optional, experiment name prefix\n",
        "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
        "    max_concurrency=4, # optional, add concurrency\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTNe4kWrplB"
      },
      "source": [
        "## Part 2: LangGraph with Helpfulness:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1wKRddbIY_S"
      },
      "source": [
        "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
        "\n",
        "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
        "\n",
        "We're going to make a few key adjustments to account for this:\n",
        "\n",
        "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
        "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTYJ8ayR5B3"
      },
      "source": [
        "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-LQ84YhyJG0w"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD7EV0HqSQcb"
      },
      "source": [
        "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oajBwLkFVi1N"
      },
      "source": [
        "#### üèóÔ∏è Activity #4:\n",
        "\n",
        "Please write markdown for the following cells to explain what each is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6rN7feNVn9f"
      },
      "source": [
        "##### Answer\n",
        "1. A `StateGraph` is created with `AgentState` as the state type\n",
        "2. `agent` node is added with function `call_model`\n",
        "3. `action` node is added with function `tool_node`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r6XXA5FJbVf",
        "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11da08410>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check = StateGraph(AgentState)\n",
        "\n",
        "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
        "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ22o2mWVrfp"
      },
      "source": [
        "##### Answer\n",
        "1. The agent node is set as the entry point of the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNWHwWxuRiLY",
        "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x75bc729039d0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXeF6xlaXOZ"
      },
      "source": [
        "##### Answer\n",
        "Three Routing Checks (in order)\n",
        "1. Tool Call Check\n",
        "If the last message has tool calls, route to the action node to execute them.\n",
        "2. Message Limit Check\n",
        "If the conversation exceeds 10 messages, force END to prevent infinite loops.\n",
        "3. Helpfulness Check\n",
        "If no tool calls are requested, use a separate LLM (GPT-4.1-mini) to evaluate whether the agent's response adequately answers the original query. The evaluator receives the initial question and final response, then judges if it's helpful or not.\n",
        "Four Possible Routes\n",
        "\"action\" ‚Üí execute tools\n",
        "\"END\" ‚Üí force stop (too many cycles)\n",
        "\"end\" ‚Üí natural termination (response is helpful)\n",
        "\"continue\" ‚Üí loop back to agent (response needs improvement)\n",
        "Purpose\n",
        "Prevents the agent from giving weak answers. If the agent responds without tool calls but the answer is inadequate, it gets routed back to try again rather than ending with a poor response. This adds quality control while maintaining the cycle limit safety mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z_Sq3A9SaV1O"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def tool_call_or_helpful(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  initial_query = state[\"messages\"][0]\n",
        "  final_response = state[\"messages\"][-1]\n",
        "\n",
        "  if len(state[\"messages\"]) > 10:\n",
        "    return \"END\"\n",
        "\n",
        "  prompt_template = \"\"\"\\\n",
        "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
        "\n",
        "  Initial Query:\n",
        "  {initial_query}\n",
        "\n",
        "  Final Response:\n",
        "  {final_response}\"\"\"\n",
        "\n",
        "  helpfullness_prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "  helpfulness_chain = helpfullness_prompt_template | helpfulness_check_model | StrOutputParser()\n",
        "\n",
        "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
        "\n",
        "  if \"Y\" in helpfulness_response:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhnBW2YVsJO"
      },
      "source": [
        "##### Answer\n",
        "Conditional edges are added, three possible routes: \n",
        "- continue: loop back to the agent node (cycle to improve)\n",
        "- action: go to action node and excute tools\n",
        "- END: terminates the graph, if the response is good enough\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTKnWMbP_8T",
        "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11da08410>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_call_or_helpful,\n",
        "    {\n",
        "        \"continue\" : \"agent\",\n",
        "        \"action\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDLEWOIVtK0"
      },
      "source": [
        "##### Answer\n",
        "`action` and `agent` nodes are connected. This basically says \"after the action node finishes executing tools, always route back to the agent node\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbDK2MbuREgU",
        "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x75bc729039d0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSI8AOaEVvT-"
      },
      "source": [
        "##### Answer\n",
        "The graph with helfulness check is compiled. This means "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oQldl8ERQ8lf"
      },
      "outputs": [],
      "source": [
        "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67FGCMRVwGz"
      },
      "source": [
        "##### Answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oo8E-PRK1T",
        "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Deep Research Agents are advanced AI systems designed to assist with in-depth research tasks. They leverage deep learning techniques and large datasets to analyze complex information, generate insights, and support decision-making across various fields such as science, technology, medicine, and more. These agents can automate literature reviews, extract relevant data from vast sources, and provide comprehensive summaries, making research more efficient and thorough. Would you like me to find more detailed or specific information about Deep Research Agents?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 158, 'total_tokens': 251, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ4p3pIKceAjbeS3g3QtsJLgucObk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b10b2082-4074-4d48-848f-37d11d18949b-0', usage_metadata={'input_tokens': 158, 'output_tokens': 93, 'total_tokens': 251, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmZPs6lnpsM"
      },
      "source": [
        "## Part 3: LangGraph for the \"Patterns\" of GenAI\n",
        "\n",
        "### Task 4: Helpfulness Check of Gen AI Pattern Descriptions\n",
        "\n",
        "Let's ask our system about the 3 main patterns in Generative AI:\n",
        "\n",
        "1. Context Engineering\n",
        "2. Fine-tuning\n",
        "3. Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZoLl7GlXoae-"
      },
      "outputs": [],
      "source": [
        "patterns = [\"Context Engineering\", \"Fine-tuning\", \"LLM-based agents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkh0YJuCp3Zl",
        "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context Engineering is a relatively new interdisciplinary field that focuses on designing, managing, and optimizing the context in which systems, especially artificial intelligence and software applications, operate. It involves understanding and shaping the environment, circumstances, and background information that influence how systems behave and interact with users. The goal is to improve system performance, user experience, and decision-making by carefully engineering the context.\n",
            "\n",
            "The concept of Context Engineering has gained prominence with the rise of AI, IoT, and complex software systems, where context plays a crucial role in system effectiveness. It started to break onto the scene in the late 2010s and early 2020s, driven by advancements in contextual AI, ubiquitous computing, and the need for more adaptive and personalized systems.\n",
            "\n",
            "Would you like me to find more detailed or specific information about its origins and development?\n",
            "\n",
            "\n",
            "\n",
            "Fine-tuning is a machine learning technique used to adapt a pre-trained model to a specific task or dataset. Instead of training a model from scratch, which can be resource-intensive and time-consuming, fine-tuning involves taking an existing model that has already learned general features from a large dataset and then further training it on a smaller, task-specific dataset. This process helps the model specialize and improve its performance on the target task while leveraging the knowledge it has already acquired.\n",
            "\n",
            "Fine-tuning has become a prominent approach in the development of large language models, computer vision models, and other deep learning architectures. It allows researchers and developers to efficiently customize models for various applications, such as natural language processing, image recognition, and more.\n",
            "\n",
            "As for when it \"broke onto the scene,\" fine-tuning has been around in various forms for many years, but it gained widespread popularity and recognition with the rise of large pre-trained models like BERT (introduced in 2018) and GPT (with GPT-2 in 2019 and GPT-3 in 2020). These models demonstrated the effectiveness of transfer learning and fine-tuning, leading to a significant shift in how AI models are developed and deployed.\n",
            "\n",
            "Would you like me to find more detailed historical information or specific milestones related to the development of fine-tuning?\n",
            "\n",
            "\n",
            "\n",
            "LLM-based agents are intelligent systems that leverage large language models (LLMs) to perform a variety of tasks, such as understanding natural language, generating human-like responses, and making decisions or taking actions based on the input they receive. These agents can be used in applications like chatbots, virtual assistants, automated customer support, and more complex decision-making systems.\n",
            "\n",
            "The concept of LLM-based agents gained significant attention and broke onto the scene around 2020-2021, coinciding with the development and release of advanced large language models like OpenAI's GPT-3 in 2020. GPT-3's impressive capabilities demonstrated the potential of LLMs to serve as foundational components for building intelligent agents that can understand and generate human language at a high level.\n",
            "\n",
            "Since then, the field has rapidly evolved, with numerous innovations in model architecture, training techniques, and applications, making LLM-based agents a prominent area of research and development in artificial intelligence.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern in patterns:\n",
        "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
        "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
        "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
        "  print(messages[\"messages\"][-1].content)\n",
        "  print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
